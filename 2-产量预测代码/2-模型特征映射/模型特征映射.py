"""
Copyright (c) 2025 å¼ å¾·æµ·
MIT Licensed - è¯¦è§é¡¹ç›®æ ¹ç›®å½• LICENSE æ–‡ä»¶

é¡¹ç›®: Meteorology-Assisted-Crop-Yield-Prediction
ä»“åº“: https://github.com/ZDH4869/Meteorology-Assisted-Crop-Yield-Prediction.git
è”ç³»: zhangdehai1412@163.com
"""
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆç‰¹å¾åç§°æ˜ å°„å·¥å…·
åŸºäºè®­ç»ƒä»£ç çš„æ·±å…¥åˆ†æï¼Œç²¾ç¡®æ˜ å°„feature_importance_AA.csvä¸­çš„featureåˆ—ååˆ°åŸå§‹æ•°æ®åˆ—å

ç‰¹å¾è½¬æ¢è¿‡ç¨‹åˆ†æï¼š
1. Weather data: åŸå§‹åˆ—å -> å°å†™è½¬æ¢ -> æ·»åŠ 'right_'å‰ç¼€ -> åˆå¹¶åé‡å‘½å
2. Soil data: åŸå§‹åˆ—å -> å°å†™è½¬æ¢ -> æ·»åŠ 'right_'å‰ç¼€ -> åˆå¹¶åé‡å‘½å
3. åæ ‡åˆ—: x, y -> x_product, y_product (äº§å“æ•°æ®åæ ‡)
4. XGBoostå¶å­ç‰¹å¾: ä»åŸå§‹ç‰¹å¾æå– -> æ·»åŠ 'feature_'å‰ç¼€ + æ•°å­—ç¼–å·
5. PCAç‰¹å¾: é™ç»´å -> æ·»åŠ 'pca_'å‰ç¼€ + æ•°å­—ç¼–å·
6. æœ€ç»ˆç‰¹å¾é¡ºåº: åæ ‡ + æ°”è±¡ + åœŸå£¤ + XGBoostå¶å­ + PCA
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional

class EnhancedFeatureMappingTool:
    """å¢å¼ºç‰ˆç‰¹å¾åç§°æ˜ å°„å·¥å…·ç±»"""
    
    def __init__(self, feature_importance_file: str, original_feature_names_file: str, output_folder: Optional[str] = None):
        """
        åˆå§‹åŒ–æ˜ å°„å·¥å…·
        
        Args:
            feature_importance_file: feature_importance_AA.csvæ–‡ä»¶è·¯å¾„
            original_feature_names_file: original_feature_names.txtæ–‡ä»¶è·¯å¾„
            output_folder: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        self.feature_importance_file = feature_importance_file
        self.original_feature_names_file = original_feature_names_file
        self.output_folder = output_folder
        
        # åŸºäºè®­ç»ƒä»£ç åˆ†æçš„åŸå§‹æ•°æ®åˆ—åå®šä¹‰
        self.weather_columns_original = [
            'Lon', 'Lat', 'altitude', 'YYYY', 'MM', 'Tsun_mean', 'TAVE_mean',
            'Tmax_mean', 'Tmin_mean', 'Rain_mean', 'GTAVE_mean', 'GTmax_mean', 'GTmin_mean', 'Sevp_mean'
        ]
        
        self.soil_columns_original = [
            'x', 'y', 'TZ', 'CEC', 'PH', 'SOC', 'SOCD', 'TK', 'TND', 'TPD'
        ]
        
        # äº§å“æ•°æ®åˆ—å
        self.product_columns_original = [
            'x', 'y', 'SUIT', 'YYYY', 'per_mu', 'per_qu'
        ]
        
        # åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®
        self.feature_importance_df = None
        self.original_feature_names = []
        self.load_data()
        
        # åˆ›å»ºç‰¹å¾æ˜ å°„å­—å…¸
        self.feature_mapping = self.create_detailed_mapping()
        
    def load_data(self):
        """åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®å’ŒåŸå§‹ç‰¹å¾åç§°"""
        try:
            # åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®
            self.feature_importance_df = pd.read_csv(self.feature_importance_file, encoding='utf-8')
            print(f"âœ… æˆåŠŸåŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®: {len(self.feature_importance_df)} ä¸ªç‰¹å¾")
            
            # åŠ è½½åŸå§‹ç‰¹å¾åç§°
            with open(self.original_feature_names_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # è§£æåŸå§‹ç‰¹å¾åç§°
            lines = content.strip().split('\n')
            for line in lines:
                if line.strip() and not line.startswith('=') and not line.startswith('åŸå§‹'):
                    # æå–ç‰¹å¾åç§°ï¼ˆå»æ‰åºå·ï¼‰
                    if '. ' in line:
                        feature_name = line.split('. ', 1)[1].strip()
                        self.original_feature_names.append(feature_name)
            
            print(f"âœ… æˆåŠŸåŠ è½½åŸå§‹ç‰¹å¾åç§°: {len(self.original_feature_names)} ä¸ªç‰¹å¾")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            raise
    
    def create_detailed_mapping(self) -> Dict[str, Dict[str, str]]:
        """
        åˆ›å»ºè¯¦ç»†çš„ç‰¹å¾æ˜ å°„å­—å…¸
        
        Returns:
            Dict[str, Dict[str, str]]: æ˜ å°„å­—å…¸ï¼ŒåŒ…å«åŸå§‹åˆ—åã€æ•°æ®æºã€ç‰¹å¾ç±»å‹ç­‰ä¿¡æ¯
        """
        mapping = {}
        
        # åŸºäºè®­ç»ƒä»£ç åˆ†æçš„ç‰¹å¾é¡ºåºå’Œè½¬æ¢è¿‡ç¨‹
        # ç‰¹å¾é¡ºåºï¼šåæ ‡åˆ—(2) + æ°”è±¡ç‰¹å¾(åŠ¨æ€) + åœŸå£¤ç‰¹å¾(åŠ¨æ€) + XGBoostå¶å­ç‰¹å¾(50) + PCAç‰¹å¾(1)
        
        for i, feature_name in enumerate(self.original_feature_names):
            feature_info = {
                'original_column_name': '',
                'data_source': 'unknown',
                'feature_type': 'unknown',
                'description': '',
                'index': i
            }
            
            if feature_name.isdigit():
                # æ•°å­—ç´¢å¼•ç‰¹å¾ï¼Œæ ¹æ®ä½ç½®æ˜ å°„
                idx = int(feature_name)
                feature_info.update(self._map_numeric_feature_detailed(idx))
            elif feature_name.startswith('feature_'):
                # XGBoostå¶å­ç‰¹å¾
                feature_info.update({
                    'original_column_name': f"XGBoost_leaf_{feature_name}",
                    'data_source': 'xgboost',
                    'feature_type': 'xgboost_leaf',
                    'description': f"XGBoostæ¨¡å‹å¶å­èŠ‚ç‚¹ç‰¹å¾ï¼Œç¼–å·{feature_name.split('_')[1]}"
                })
            elif feature_name.startswith('pca_'):
                # PCAç‰¹å¾
                feature_info.update({
                    'original_column_name': f"PCA_{feature_name}",
                    'data_source': 'pca',
                    'feature_type': 'pca_component',
                    'description': f"PCAé™ç»´åçš„ä¸»æˆåˆ†ï¼Œç¼–å·{feature_name.split('_')[1]}"
                })
            else:
                feature_info.update({
                    'original_column_name': f"unknown_{feature_name}",
                    'data_source': 'unknown',
                    'feature_type': 'unknown',
                    'description': f"æœªçŸ¥ç‰¹å¾ç±»å‹: {feature_name}"
                })
            
            mapping[feature_name] = feature_info
        
        return mapping
    
    def _map_numeric_feature_detailed(self, idx: int) -> Dict[str, str]:
        """
        å°†æ•°å­—ç´¢å¼•æ˜ å°„åˆ°è¯¦ç»†çš„åŸå§‹åˆ—åä¿¡æ¯
        
        Args:
            idx: ç‰¹å¾ç´¢å¼•
            
        Returns:
            Dict[str, str]: ç‰¹å¾è¯¦ç»†ä¿¡æ¯
        """
        # åŸºäºè®­ç»ƒä»£ç åˆ†æçš„ç‰¹å¾é¡ºåº
        # 0-1: åæ ‡åˆ—
        if idx == 0:
            return {
                'original_column_name': 'x_product',
                'data_source': 'coordinate',
                'feature_type': 'coordinate',
                'description': 'äº§å“æ•°æ®xåæ ‡ï¼ˆç»åº¦ï¼‰'
            }
        elif idx == 1:
            return {
                'original_column_name': 'y_product',
                'data_source': 'coordinate',
                'feature_type': 'coordinate',
                'description': 'äº§å“æ•°æ®yåæ ‡ï¼ˆçº¬åº¦ï¼‰'
            }
        
        # 2-30: æ°”è±¡ç‰¹å¾ (åŠ¨æ€è®¡ç®—ç‰¹å¾æ•°é‡)
        elif 2 <= idx <= (1 + len(self.weather_columns_original)):
            weather_idx = idx - 2
            if weather_idx < len(self.weather_columns_original):
                original_name = self.weather_columns_original[weather_idx]
                # è½¬æ¢ä¸ºå°å†™å¹¶æ·»åŠ right_å‰ç¼€ï¼ˆåŸºäºè®­ç»ƒä»£ç ï¼‰
                mapped_name = f"right_{original_name.lower()}"
                
                # æ ¹æ®åˆ—åç¡®å®šæ°”è±¡ç‰¹å¾ç±»å‹
                if 'tsun' in original_name.lower():
                    feature_type = 'sunshine'
                elif 'tave' in original_name.lower():
                    feature_type = 'temperature_avg'
                elif 'tmax' in original_name.lower():
                    feature_type = 'temperature_max'
                elif 'tmin' in original_name.lower():
                    feature_type = 'temperature_min'
                elif 'rain' in original_name.lower():
                    feature_type = 'precipitation'
                elif 'gtave' in original_name.lower():
                    feature_type = 'ground_temperature_avg'
                elif 'gtmax' in original_name.lower():
                    feature_type = 'ground_temperature_max'
                elif 'gtmin' in original_name.lower():
                    feature_type = 'ground_temperature_min'
                elif 'sevp' in original_name.lower():
                    feature_type = 'evaporation'
                elif 'altitude' in original_name.lower():
                    feature_type = 'elevation'
                elif 'yyyy' in original_name.lower():
                    feature_type = 'year'
                elif 'mm' in original_name.lower():
                    feature_type = 'month'
                elif 'lon' in original_name.lower():
                    feature_type = 'longitude'
                elif 'lat' in original_name.lower():
                    feature_type = 'latitude'
                else:
                    feature_type = 'weather_other'
                
                return {
                    'original_column_name': mapped_name,
                    'data_source': 'weather',
                    'feature_type': feature_type,
                    'description': f"æ°”è±¡æ•°æ®: {original_name} -> {mapped_name}"
                }

        # åœŸå£¤ç‰¹å¾ (åŠ¨æ€è®¡ç®—ç‰¹å¾æ•°é‡)
        elif (2 + len(self.weather_columns_original)) <= idx <= (1 + len(self.weather_columns_original) + len(self.soil_columns_original)):
            soil_idx = idx - (2 + len(self.weather_columns_original))
            if soil_idx < len(self.soil_columns_original):
                original_name = self.soil_columns_original[soil_idx]
                # è½¬æ¢ä¸ºå°å†™å¹¶æ·»åŠ right_å‰ç¼€
                mapped_name = f"right_{original_name.lower()}"

                # æ ¹æ®åˆ—åç¡®å®šåœŸå£¤ç‰¹å¾ç±»å‹
                if original_name == 'TZ':
                    feature_type = 'soil_texture'
                elif original_name == 'CEC':
                    feature_type = 'soil_cation_exchange'
                elif original_name == 'PH':
                    feature_type = 'soil_ph'
                elif original_name in ['SOC', 'SOCD']:
                    feature_type = 'soil_organic_carbon'
                elif original_name == 'TK':
                    feature_type = 'soil_potassium'
                elif original_name == 'TND':
                    feature_type = 'soil_nitrogen'
                elif original_name == 'TPD':
                    feature_type = 'soil_phosphorus'
                elif original_name in ['x', 'y']:
                    feature_type = 'coordinate'
                else:
                    feature_type = 'soil_other'

                return {
                    'original_column_name': mapped_name,
                    'data_source': 'soil',
                    'feature_type': feature_type,
                    'description': f"åœŸå£¤æ•°æ®: {original_name} -> {mapped_name}"
                }
        
        # å…¶ä»–ç‰¹å¾
        else:
            return {
                'original_column_name': f"unknown_feature_{idx}",
                'data_source': 'unknown',
                'feature_type': 'unknown',
                'description': f"æœªçŸ¥ç‰¹å¾ï¼Œç´¢å¼•{idx}"
            }
    
    def generate_mapping_results(self) -> pd.DataFrame:
        """
        ç”Ÿæˆå®Œæ•´çš„æ˜ å°„ç»“æœDataFrame
        
        Returns:
            pd.DataFrame: åŒ…å«æ‰€æœ‰æ˜ å°„ä¿¡æ¯çš„DataFrame
        """
        results = []
        
        for _, row in self.feature_importance_df.iterrows():
            feature_name = row['feature']
            importance = row['importance']
            relative_importance = row['relative_importance']
            
            if feature_name in self.feature_mapping:
                mapping_info = self.feature_mapping[feature_name]
                results.append({
                    'feature': feature_name,
                    'importance': importance,
                    'relative_importance': relative_importance,
                    'original_column_name': mapping_info['original_column_name'],
                    'data_source': mapping_info['data_source'],
                    'feature_type': mapping_info['feature_type'],
                    'description': mapping_info['description'],
                    'index': mapping_info['index']
                })
            else:
                results.append({
                    'feature': feature_name,
                    'importance': importance,
                    'relative_importance': relative_importance,
                    'original_column_name': f"unknown_{feature_name}",
                    'data_source': 'unknown',
                    'feature_type': 'unknown',
                    'description': f"æœªæ‰¾åˆ°æ˜ å°„ä¿¡æ¯: {feature_name}",
                    'index': -1
                })
        
        return pd.DataFrame(results)
    
    def generate_detailed_report(self) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„æ˜ å°„æŠ¥å‘Š
        
        Returns:
            str: æ˜ å°„æŠ¥å‘Š
        """
        mapped_df = self.generate_mapping_results()
        
        report = []
        report.append("=" * 100)
        report.append("å¢å¼ºç‰ˆç‰¹å¾åç§°æ˜ å°„æŠ¥å‘Š")
        report.append("åŸºäºè®­ç»ƒä»£ç æ·±åº¦åˆ†æçš„ç‰¹å¾è½¬æ¢è¿‡ç¨‹")
        report.append("=" * 100)
        report.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        report.append("1. ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:")
        report.append(f"   æ€»ç‰¹å¾æ•°: {len(mapped_df)}")
        
        # æŒ‰æ•°æ®æºç»Ÿè®¡
        data_source_stats = mapped_df['data_source'].value_counts()
        for source, count in data_source_stats.items():
            report.append(f"   {source.upper()}: {count} ä¸ªç‰¹å¾")
        
        report.append("")
        
        # æŒ‰ç‰¹å¾ç±»å‹ç»Ÿè®¡
        report.append("2. æŒ‰ç‰¹å¾ç±»å‹ç»Ÿè®¡:")
        feature_type_stats = mapped_df['feature_type'].value_counts()
        for ftype, count in feature_type_stats.items():
            report.append(f"   {ftype.upper()}: {count} ä¸ªç‰¹å¾")
        
        report.append("")
        
        # æœ€é‡è¦çš„ç‰¹å¾æ˜ å°„
        report.append("3. å‰20ä¸ªæœ€é‡è¦çš„ç‰¹å¾æ˜ å°„:")
        report.append("-" * 100)
        report.append(f"{'æ’å':<4} {'ç‰¹å¾å':<15} {'åŸå§‹åˆ—å':<25} {'æ•°æ®æº':<10} {'ç‰¹å¾ç±»å‹':<15} {'é‡è¦æ€§':<10}")
        report.append("-" * 100)
        
        for idx, row in mapped_df.head(20).iterrows():
            rank = idx + 1
            feature = row['feature']
            original = row['original_column_name']
            source = row['data_source']
            ftype = row['feature_type']
            importance = f"{row['relative_importance']:.6f}"
            
            report.append(f"{rank:<4} {feature:<15} {original:<25} {source:<10} {ftype:<15} {importance:<10}")
        
        report.append("")
        
        # æŒ‰æ•°æ®æºåˆ†ç»„çš„è¯¦ç»†ç‰¹å¾
        report.append("4. æŒ‰æ•°æ®æºåˆ†ç»„çš„è¯¦ç»†ç‰¹å¾:")
        for source in ['weather', 'soil', 'coordinate', 'xgboost', 'pca', 'unknown']:
            source_features = mapped_df[mapped_df['data_source'] == source]
            if len(source_features) > 0:
                report.append(f"\n{source.upper()} æ•°æ®æº ({len(source_features)} ä¸ªç‰¹å¾):")
                report.append("-" * 80)
                
                for _, row in source_features.iterrows():
                    report.append(f"  {row['feature']} -> {row['original_column_name']}")
                    report.append(f"    ç±»å‹: {row['feature_type']}, é‡è¦æ€§: {row['relative_importance']:.6f}")
                    report.append(f"    æè¿°: {row['description']}")
                    report.append("")
        
        # æ°”è±¡ç‰¹å¾è¯¦ç»†åˆ†æ
        weather_features = mapped_df[mapped_df['data_source'] == 'weather']
        if len(weather_features) > 0:
            report.append("5. æ°”è±¡ç‰¹å¾è¯¦ç»†åˆ†æ:")
            report.append("-" * 80)
            
            # æŒ‰æ°”è±¡ç‰¹å¾ç±»å‹åˆ†ç»„
            weather_type_stats = weather_features['feature_type'].value_counts()
            for wtype, count in weather_type_stats.items():
                report.append(f"  {wtype.upper()}: {count} ä¸ªç‰¹å¾")
                type_features = weather_features[weather_features['feature_type'] == wtype]
                for _, row in type_features.iterrows():
                    report.append(f"    {row['feature']} -> {row['original_column_name']} (é‡è¦æ€§: {row['relative_importance']:.6f})")
                report.append("")
        
        # åœŸå£¤ç‰¹å¾è¯¦ç»†åˆ†æ
        soil_features = mapped_df[mapped_df['data_source'] == 'soil']
        if len(soil_features) > 0:
            report.append("6. åœŸå£¤ç‰¹å¾è¯¦ç»†åˆ†æ:")
            report.append("-" * 80)
            
            # æŒ‰åœŸå£¤ç‰¹å¾ç±»å‹åˆ†ç»„
            soil_type_stats = soil_features['feature_type'].value_counts()
            for stype, count in soil_type_stats.items():
                report.append(f"  {stype.upper()}: {count} ä¸ªç‰¹å¾")
                type_features = soil_features[soil_features['feature_type'] == stype]
                for _, row in type_features.iterrows():
                    report.append(f"    {row['feature']} -> {row['original_column_name']} (é‡è¦æ€§: {row['relative_importance']:.6f})")
                report.append("")
        
        return "\n".join(report)
    
    def save_results(self, output_csv: str = None, output_report: str = None):
        """
        ä¿å­˜æ˜ å°„ç»“æœ
        
        Args:
            output_csv: CSVè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            output_report: æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        # ç”Ÿæˆç»“æœ
        mapped_df = self.generate_mapping_results()
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_csv is None:
            output_csv = os.path.join(self.output_folder or ".", "enhanced_feature_mapping_results.csv")
        if output_report is None:
            output_report = os.path.join(self.output_folder or ".", "enhanced_feature_mapping_report.txt")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_csv)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜CSV
        mapped_df.to_csv(output_csv, index=False, encoding='utf-8')
        print(f"âœ… å¢å¼ºç‰ˆæ˜ å°„ç»“æœå·²ä¿å­˜è‡³: {output_csv}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report = self.generate_detailed_report()
        with open(output_report, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… å¢å¼ºç‰ˆè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_report}")
        
        return mapped_df


def main():
    """ä¸»å‡½æ•°"""
    # æ–‡ä»¶è·¯å¾„
    feature_importance_file = r"2. B774æ¨¡å‹è„šæœ¬\2-é€‚å®œåº¦äº§é‡é¢„æµ‹æ¨¡å‹\model_test_06\feature_importanceAA\feature_importance_AA.csv"
    original_feature_names_file = r"2. B774æ¨¡å‹è„šæœ¬\2-é€‚å®œåº¦äº§é‡é¢„æµ‹æ¨¡å‹\model_test_06\feature_importanceAA\original_feature_names.txt"
    
    # å‚æ•°è®¾ç½®ï¼šè¾“å‡ºæ–‡ä»¶å¤¹
    output_folder = r"2. B774æ¨¡å‹è„šæœ¬\2-é€‚å®œåº¦äº§é‡é¢„æµ‹æ¨¡å‹\model_test_06\feature_importanceAA"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    timestamped_folder = os.path.join(output_folder, f"mapping_results_{timestamp}")
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(timestamped_folder, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {timestamped_folder}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(feature_importance_file):
        print(f"âŒ ç‰¹å¾é‡è¦æ€§æ–‡ä»¶ä¸å­˜åœ¨: {feature_importance_file}")
        return
    
    if not os.path.exists(original_feature_names_file):
        print(f"âŒ åŸå§‹ç‰¹å¾åç§°æ–‡ä»¶ä¸å­˜åœ¨: {original_feature_names_file}")
        return
    
    try:
        # åˆ›å»ºå¢å¼ºç‰ˆæ˜ å°„å·¥å…·
        print("ğŸ”§ åˆ›å»ºå¢å¼ºç‰ˆç‰¹å¾æ˜ å°„å·¥å…·...")
        mapping_tool = EnhancedFeatureMappingTool(feature_importance_file, original_feature_names_file, timestamped_folder)
        
        # ç”Ÿæˆæ˜ å°„ç»“æœ
        print("ğŸ“Š ç”Ÿæˆå¢å¼ºç‰ˆç‰¹å¾æ˜ å°„ç»“æœ...")
        mapped_df = mapping_tool.save_results()
        
        # æ˜¾ç¤ºå‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾æ˜ å°„
        print("\nğŸ“‹ å‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾æ˜ å°„:")
        print("-" * 100)
        print(f"{'æ’å':<4} {'ç‰¹å¾å':<15} {'åŸå§‹åˆ—å':<25} {'æ•°æ®æº':<10} {'ç‰¹å¾ç±»å‹':<15} {'é‡è¦æ€§':<10}")
        print("-" * 100)
        
        for idx, row in mapped_df.head(10).iterrows():
            rank = idx + 1
            feature = row['feature']
            original = row['original_column_name']
            source = row['data_source']
            ftype = row['feature_type']
            importance = f"{row['relative_importance']:.6f}"
            print(f"{rank:<4} {feature:<15} {original:<25} {source:<10} {ftype:<15} {importance:<10}")
        
        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“ˆ ç‰¹å¾æ˜ å°„ç»Ÿè®¡æ‘˜è¦:")
        print(f"   æ€»ç‰¹å¾æ•°: {len(mapped_df)}")
        
        # æŒ‰æ•°æ®æºç»Ÿè®¡
        data_source_stats = mapped_df['data_source'].value_counts()
        for source, count in data_source_stats.items():
            print(f"   {source.upper()}: {count} ä¸ªç‰¹å¾")
        
        # æŒ‰ç‰¹å¾ç±»å‹ç»Ÿè®¡
        print("\nğŸ“Š æŒ‰ç‰¹å¾ç±»å‹ç»Ÿè®¡:")
        feature_type_stats = mapped_df['feature_type'].value_counts()
        for ftype, count in feature_type_stats.items():
            print(f"   {ftype.upper()}: {count} ä¸ªç‰¹å¾")
        
        print("\nâœ… å¢å¼ºç‰ˆç‰¹å¾æ˜ å°„å®Œæˆï¼")
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹:")
        print(f"   {timestamped_folder}")
        print("ğŸ“„ è¾“å‡ºæ–‡ä»¶:")
        print("   - enhanced_feature_mapping_results.csv: è¯¦ç»†æ˜ å°„ç»“æœ")
        print("   - enhanced_feature_mapping_report.txt: å®Œæ•´æ˜ å°„æŠ¥å‘Š")
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾æ˜ å°„å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
